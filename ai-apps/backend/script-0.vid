//#initialstate L1 serverless.yml

//#typein L1 serverless.yml
service: ai-app-backend
plugins:
  - serverless-plugin-typescript

useDotenv:#INPUTPAUSE# true

provider#INPUTPAUSE#:
  name: aws
  runtime: nodejs18.x
  #INPUTPAUSE#stackName: ai-app-backend
  #INPUTPAUSE#region: eu-west-2
  versionFunctions: false
  #INPUTPAUSE#deploymentBucket: ${env:DEPLOY_BUCKET}
  environment:    
    #INPUTPAUSE#OPENAI_KEY: ${env:OPENAI_KEY}

//#initialstate L1 handler.ts

//#typein L1 handler.ts "Make sure you have run npm install!"

const env = <{ OPENAI_KEY: string }>process.env;

export #INPUTPAUSE#async function main(event: APIGatewayEvent, context: Context) {
    return #INPUTPAUSE#{
        statusCode: 200,
        headers: {
        },
    };
}

//#typein L1 handler.ts
import { APIGatewayEvent, APIGatewayEventRequestContext, Context } from "aws-lambda";

//#typein L16 serverless.yml
functions:
  callchatgpt:
    handler: #AUTOPAUSE#handler.main
    #INPUTPAUSE#url: true

//#typein L2 handler.ts
import OpenAI from "openai";

//#typein L6 handler.ts
type RequestBody = {
    subject: string
};


//#typein L11 handler.ts
    const body = <RequestBody>JSON.parse(event.body!);

//#initialstate L1 debug.ts

//#typein L1 debug.ts
import { APIGatewayEvent, Context, SNSEvent } from "aws-lambda";
import { main } from "./handler.js";

main(#INPUTPAUSE#{
    body: JSON.stringify({ subject: 'trains' })
} as APIGatewayEvent, {} as Context)
.catch#INPUTPAUSE#(e => {
    console.error(e);
    debugger;
})

//#typein L12 handler.ts
    if (!body || !body.subject) return { 
        statusCode: 400, 
        body: #INPUTPAUSE#JSON.stringify({ message: 'Invalid request' })
    };


//#typein L16 handler.ts
    const openai = new OpenAI({ apiKey: env.OPENAI_KEY });

    const prompt = #INPUTPAUSE#`Tell me a joke about ${body.subject}`;

    const gptResponse = await openai.chat.completions.create#INPUTPAUSE#({
        model: #INPUTPAUSE#"gpt-3.5-turbo",
        messages: [
            #INPUTPAUSE#{
                role: "user",
                content: prompt
            }
        ]
    });

    const result = gptResponse#INPUTPAUSE#.choices[0].message.content;

//#typein L36 handler.ts
        body: result
