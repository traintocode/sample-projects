//#initialstate L1 handler.ts
import { APIGatewayEvent, APIGatewayEventRequestContext, Context } from "aws-lambda";
import OpenAI from "openai";

const env = <{ OPENAI_KEY: string }>process.env;

type RequestBody = {
    subject: string
};

export async function main(event: APIGatewayEvent, context: Context) {
    const body = <RequestBody>JSON.parse(event.body!);
    if (!body || !body.subject) return { 
        statusCode: 400, 
        body: JSON.stringify({ message: 'Invalid request' })
    };
    const openai = new OpenAI({ apiKey: env.OPENAI_KEY });

    const prompt = `Tell me a joke about ${body.subject}`;

    const gptResponse = await openai.chat.completions.create({
        model: "gpt-3.5-turbo",
        messages: [
            {
                role: "user",
                content: prompt
            }
        ]
    });

    const result = gptResponse.choices[0].message.content;

    return {
        statusCode: 200,
        headers: {
            ["Access-Control-Allow-Origin"]: "http://localhost:5173"
        },
        body: result
    };
}

//#replace L18C20 handler.ts
Create a cartoon image of ${body.subject}`;
//#deletefrom L20 handler.ts
//#deletefrom L20 handler.ts
//#deletefrom L20 handler.ts
//#deletefrom L20 handler.ts
//#deletefrom L20 handler.ts
//#deletefrom L20 handler.ts
//#deletefrom L20 handler.ts
//#deletefrom L20 handler.ts
//#deletefrom L20 handler.ts
//#deletefrom L20 handler.ts
//#deletefrom L20 handler.ts
//#typein L20 handler.ts
    const gptResponse = await openai.images.generate({
        prompt,
        model: "dall-e-3",
        response_format: "url"
    });

//#typein L25 handler.ts
    const result = gptResponse.data[0].url;
